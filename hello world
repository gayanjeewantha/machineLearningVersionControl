
import spacy
nlp = spacy.load('en')                  #   load the default model which is english-croe-web
                                        #   nlp object use for create documents,access linguistic annotations and different
                                        #   nlp properties
print('Hello World')
document = unicode(open('testData.txt').read().decode('utf8'))
document = nlp(document)
dir(document)
print dir(document)
print document[0]
print 'all tags are below'



all_tags = {w.pos: w.pos_ for w in document}
print all_tags

for word in list(document.sents)[0]:
    print word, word.tag_

#define some parameters
noisy_pos_tags = ['PROP']
min_token_length = 2



#Function to check if the token is a noise or not
def isNoise(token):
    is_noise = False
    if token.pos_ in noisy_pos_tags:
        is_noise = True
    elif token.is_stop == True:
        is_noise = True
    elif len(token.string) <= min_token_length:
        is_noise = True
    return is_noise
def cleanup(token, lower = True):
    if lower:
       token = token.lower()
    return token.strip()

from collections import Counter
cleaned_list = [cleanup(word.string) for word in document if not isNoise(word)]
Counter(cleaned_list) .most_common(5)

print cleaned_list

print 'before print entities'
#entity detection
labels = set([w.label_ for w in document.ents])
for label in labels:
    entities = [cleanup(e.string, lower=False) for e in document.ents if label==e.label_]
    entities = list(set(entities))
    print label,entities

    # extract all review sentences that contains the term - hotel
    hotel = [sent for sent in document.sents if 'hotel' in sent.string.lower()]


#Dependency Parsing

# extract all review sentences that contains the term - hotel
hotel = [sent for sent in document.sents if 'hotel' in sent.string.lower()]

print "Before edite the screen"

print hotel

print '=================================='

sentence = hotel[2]
for word in sentence:
    print word, ':' , str(list(word.children))



print '==================================='

# check all adjectives used with a word
def pos_words (sentence, token, ptag):
    sentences = [sent for sent in sentence.sents if token in sent.string]
    pwrds = []
    for sent in sentences:
        for word in sent:
            for character in word.string:
                   pwrds.extend([child.string.strip() for child in word.children
                                                      if child.pos_ == ptag] )
    return Counter(pwrds).most_common(10)

print pos_words(document, 'hotel', 'ADJ')

# Generate Noun Phrases
doc = nlp(u'I love data science on analytics vidhya')
for np in doc.noun_chunks:
    print np.text, np.root.dep_, np.root.head.text
